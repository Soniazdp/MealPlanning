{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "!export HF_HOME=\"/scratch/ssd004/scratch/lfy\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_cpp import Llama, LlamaGrammar\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed: int):\n",
    "    import random, os\n",
    "    import numpy as np\n",
    "    import torch\n",
    "    \n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    \n",
    "seed_everything(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_model_loader: loaded meta data with 27 key-value pairs and 291 tensors from /checkpoint/lfy/14024697/models--QuantFactory--Meta-Llama-3.1-8B-Instruct-GGUF/snapshots/b6d5cca03f341fd97b7657420bd60e070835b7e5/./Meta-Llama-3.1-8B-Instruct.Q4_K_M.gguf (version GGUF V3 (latest))\n",
      "llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.\n",
      "llama_model_loader: - kv   0:                       general.architecture str              = llama\n",
      "llama_model_loader: - kv   1:                               general.type str              = model\n",
      "llama_model_loader: - kv   2:                               general.name str              = Models\n",
      "llama_model_loader: - kv   3:                         general.size_label str              = 8.0B\n",
      "llama_model_loader: - kv   4:                            general.license str              = llama3.1\n",
      "llama_model_loader: - kv   5:                               general.tags arr[str,6]       = [\"facebook\", \"meta\", \"pytorch\", \"llam...\n",
      "llama_model_loader: - kv   6:                          general.languages arr[str,8]       = [\"en\", \"de\", \"fr\", \"it\", \"pt\", \"hi\", ...\n",
      "llama_model_loader: - kv   7:                          llama.block_count u32              = 32\n",
      "llama_model_loader: - kv   8:                       llama.context_length u32              = 131072\n",
      "llama_model_loader: - kv   9:                     llama.embedding_length u32              = 4096\n",
      "llama_model_loader: - kv  10:                  llama.feed_forward_length u32              = 14336\n",
      "llama_model_loader: - kv  11:                 llama.attention.head_count u32              = 32\n",
      "llama_model_loader: - kv  12:              llama.attention.head_count_kv u32              = 8\n",
      "llama_model_loader: - kv  13:                       llama.rope.freq_base f32              = 500000.000000\n",
      "llama_model_loader: - kv  14:     llama.attention.layer_norm_rms_epsilon f32              = 0.000010\n",
      "llama_model_loader: - kv  15:                          general.file_type u32              = 15\n",
      "llama_model_loader: - kv  16:                           llama.vocab_size u32              = 128256\n",
      "llama_model_loader: - kv  17:                 llama.rope.dimension_count u32              = 128\n",
      "llama_model_loader: - kv  18:                       tokenizer.ggml.model str              = gpt2\n",
      "llama_model_loader: - kv  19:                         tokenizer.ggml.pre str              = smaug-bpe\n",
      "llama_model_loader: - kv  20:                      tokenizer.ggml.tokens arr[str,128256]  = [\"!\", \"\\\"\", \"#\", \"$\", \"%\", \"&\", \"'\", ...\n",
      "llama_model_loader: - kv  21:                  tokenizer.ggml.token_type arr[i32,128256]  = [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...\n",
      "llama_model_loader: - kv  22:                      tokenizer.ggml.merges arr[str,280147]  = [\"Ġ Ġ\", \"Ġ ĠĠĠ\", \"ĠĠ ĠĠ\", \"...\n",
      "llama_model_loader: - kv  23:                tokenizer.ggml.bos_token_id u32              = 128000\n",
      "llama_model_loader: - kv  24:                tokenizer.ggml.eos_token_id u32              = 128009\n",
      "llama_model_loader: - kv  25:                    tokenizer.chat_template str              = {% set loop_messages = messages %}{% ...\n",
      "llama_model_loader: - kv  26:               general.quantization_version u32              = 2\n",
      "llama_model_loader: - type  f32:   65 tensors\n",
      "llama_model_loader: - type q4_K:  193 tensors\n",
      "llama_model_loader: - type q6_K:   33 tensors\n",
      "llm_load_vocab: control token: 128254 '<|reserved_special_token_246|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128249 '<|reserved_special_token_241|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128246 '<|reserved_special_token_238|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128243 '<|reserved_special_token_235|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128242 '<|reserved_special_token_234|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128241 '<|reserved_special_token_233|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128240 '<|reserved_special_token_232|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128235 '<|reserved_special_token_227|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128231 '<|reserved_special_token_223|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128230 '<|reserved_special_token_222|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128228 '<|reserved_special_token_220|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128225 '<|reserved_special_token_217|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128218 '<|reserved_special_token_210|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128214 '<|reserved_special_token_206|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128213 '<|reserved_special_token_205|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128207 '<|reserved_special_token_199|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128206 '<|reserved_special_token_198|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128204 '<|reserved_special_token_196|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128200 '<|reserved_special_token_192|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128199 '<|reserved_special_token_191|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128198 '<|reserved_special_token_190|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128196 '<|reserved_special_token_188|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128194 '<|reserved_special_token_186|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128193 '<|reserved_special_token_185|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128188 '<|reserved_special_token_180|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128187 '<|reserved_special_token_179|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128185 '<|reserved_special_token_177|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128184 '<|reserved_special_token_176|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128180 '<|reserved_special_token_172|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128179 '<|reserved_special_token_171|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128178 '<|reserved_special_token_170|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128177 '<|reserved_special_token_169|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128176 '<|reserved_special_token_168|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128175 '<|reserved_special_token_167|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128171 '<|reserved_special_token_163|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128170 '<|reserved_special_token_162|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128169 '<|reserved_special_token_161|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128168 '<|reserved_special_token_160|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128165 '<|reserved_special_token_157|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128162 '<|reserved_special_token_154|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128158 '<|reserved_special_token_150|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128156 '<|reserved_special_token_148|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128155 '<|reserved_special_token_147|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128154 '<|reserved_special_token_146|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128151 '<|reserved_special_token_143|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128149 '<|reserved_special_token_141|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128147 '<|reserved_special_token_139|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128146 '<|reserved_special_token_138|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128144 '<|reserved_special_token_136|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128142 '<|reserved_special_token_134|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128141 '<|reserved_special_token_133|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128138 '<|reserved_special_token_130|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128136 '<|reserved_special_token_128|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128135 '<|reserved_special_token_127|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128134 '<|reserved_special_token_126|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128133 '<|reserved_special_token_125|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128131 '<|reserved_special_token_123|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128128 '<|reserved_special_token_120|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128124 '<|reserved_special_token_116|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128123 '<|reserved_special_token_115|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128122 '<|reserved_special_token_114|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128119 '<|reserved_special_token_111|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128115 '<|reserved_special_token_107|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128112 '<|reserved_special_token_104|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128110 '<|reserved_special_token_102|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128109 '<|reserved_special_token_101|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128108 '<|reserved_special_token_100|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128106 '<|reserved_special_token_98|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128103 '<|reserved_special_token_95|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128102 '<|reserved_special_token_94|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128101 '<|reserved_special_token_93|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128097 '<|reserved_special_token_89|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128091 '<|reserved_special_token_83|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128090 '<|reserved_special_token_82|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128089 '<|reserved_special_token_81|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128087 '<|reserved_special_token_79|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128085 '<|reserved_special_token_77|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128081 '<|reserved_special_token_73|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128078 '<|reserved_special_token_70|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128076 '<|reserved_special_token_68|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128075 '<|reserved_special_token_67|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128073 '<|reserved_special_token_65|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128068 '<|reserved_special_token_60|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128067 '<|reserved_special_token_59|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128065 '<|reserved_special_token_57|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128063 '<|reserved_special_token_55|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128062 '<|reserved_special_token_54|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128060 '<|reserved_special_token_52|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128059 '<|reserved_special_token_51|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128057 '<|reserved_special_token_49|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128054 '<|reserved_special_token_46|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128046 '<|reserved_special_token_38|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128045 '<|reserved_special_token_37|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128044 '<|reserved_special_token_36|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128043 '<|reserved_special_token_35|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128038 '<|reserved_special_token_30|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128036 '<|reserved_special_token_28|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128035 '<|reserved_special_token_27|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128032 '<|reserved_special_token_24|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128028 '<|reserved_special_token_20|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128027 '<|reserved_special_token_19|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128024 '<|reserved_special_token_16|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128023 '<|reserved_special_token_15|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128022 '<|reserved_special_token_14|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128021 '<|reserved_special_token_13|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128018 '<|reserved_special_token_10|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128016 '<|reserved_special_token_8|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128015 '<|reserved_special_token_7|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128013 '<|reserved_special_token_5|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128011 '<|reserved_special_token_3|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128005 '<|reserved_special_token_2|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128004 '<|finetune_right_pad_id|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128002 '<|reserved_special_token_0|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128252 '<|reserved_special_token_244|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128190 '<|reserved_special_token_182|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128183 '<|reserved_special_token_175|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128137 '<|reserved_special_token_129|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128182 '<|reserved_special_token_174|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128040 '<|reserved_special_token_32|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128048 '<|reserved_special_token_40|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128092 '<|reserved_special_token_84|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128215 '<|reserved_special_token_207|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128107 '<|reserved_special_token_99|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128208 '<|reserved_special_token_200|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128145 '<|reserved_special_token_137|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128031 '<|reserved_special_token_23|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128129 '<|reserved_special_token_121|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128201 '<|reserved_special_token_193|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128074 '<|reserved_special_token_66|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128095 '<|reserved_special_token_87|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128186 '<|reserved_special_token_178|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128143 '<|reserved_special_token_135|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128229 '<|reserved_special_token_221|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128007 '<|end_header_id|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128055 '<|reserved_special_token_47|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128056 '<|reserved_special_token_48|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128061 '<|reserved_special_token_53|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128153 '<|reserved_special_token_145|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128152 '<|reserved_special_token_144|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128212 '<|reserved_special_token_204|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128172 '<|reserved_special_token_164|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128160 '<|reserved_special_token_152|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128041 '<|reserved_special_token_33|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128181 '<|reserved_special_token_173|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128094 '<|reserved_special_token_86|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128118 '<|reserved_special_token_110|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128236 '<|reserved_special_token_228|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128148 '<|reserved_special_token_140|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128042 '<|reserved_special_token_34|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128139 '<|reserved_special_token_131|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128173 '<|reserved_special_token_165|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128239 '<|reserved_special_token_231|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128157 '<|reserved_special_token_149|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128052 '<|reserved_special_token_44|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128026 '<|reserved_special_token_18|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128003 '<|reserved_special_token_1|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128019 '<|reserved_special_token_11|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128116 '<|reserved_special_token_108|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128161 '<|reserved_special_token_153|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128226 '<|reserved_special_token_218|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128159 '<|reserved_special_token_151|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128012 '<|reserved_special_token_4|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128088 '<|reserved_special_token_80|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128163 '<|reserved_special_token_155|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128001 '<|end_of_text|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128113 '<|reserved_special_token_105|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128250 '<|reserved_special_token_242|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128125 '<|reserved_special_token_117|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128053 '<|reserved_special_token_45|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128224 '<|reserved_special_token_216|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128247 '<|reserved_special_token_239|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128251 '<|reserved_special_token_243|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128216 '<|reserved_special_token_208|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128006 '<|start_header_id|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128211 '<|reserved_special_token_203|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128077 '<|reserved_special_token_69|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128237 '<|reserved_special_token_229|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128086 '<|reserved_special_token_78|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128227 '<|reserved_special_token_219|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128058 '<|reserved_special_token_50|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128100 '<|reserved_special_token_92|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128209 '<|reserved_special_token_201|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128084 '<|reserved_special_token_76|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128071 '<|reserved_special_token_63|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128070 '<|reserved_special_token_62|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128049 '<|reserved_special_token_41|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128197 '<|reserved_special_token_189|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128072 '<|reserved_special_token_64|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128000 '<|begin_of_text|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128223 '<|reserved_special_token_215|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128217 '<|reserved_special_token_209|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128111 '<|reserved_special_token_103|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128203 '<|reserved_special_token_195|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128051 '<|reserved_special_token_43|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128030 '<|reserved_special_token_22|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128117 '<|reserved_special_token_109|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128010 '<|python_tag|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128238 '<|reserved_special_token_230|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128255 '<|reserved_special_token_247|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128202 '<|reserved_special_token_194|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128132 '<|reserved_special_token_124|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128248 '<|reserved_special_token_240|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128167 '<|reserved_special_token_159|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128127 '<|reserved_special_token_119|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128105 '<|reserved_special_token_97|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128039 '<|reserved_special_token_31|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128232 '<|reserved_special_token_224|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128166 '<|reserved_special_token_158|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128130 '<|reserved_special_token_122|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128114 '<|reserved_special_token_106|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128234 '<|reserved_special_token_226|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128191 '<|reserved_special_token_183|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128064 '<|reserved_special_token_56|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128140 '<|reserved_special_token_132|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128096 '<|reserved_special_token_88|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128098 '<|reserved_special_token_90|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128192 '<|reserved_special_token_184|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128093 '<|reserved_special_token_85|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128150 '<|reserved_special_token_142|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128222 '<|reserved_special_token_214|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128233 '<|reserved_special_token_225|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128220 '<|reserved_special_token_212|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128034 '<|reserved_special_token_26|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128033 '<|reserved_special_token_25|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128253 '<|reserved_special_token_245|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128195 '<|reserved_special_token_187|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128099 '<|reserved_special_token_91|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128189 '<|reserved_special_token_181|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128210 '<|reserved_special_token_202|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128174 '<|reserved_special_token_166|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128083 '<|reserved_special_token_75|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128080 '<|reserved_special_token_72|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128104 '<|reserved_special_token_96|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128082 '<|reserved_special_token_74|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128219 '<|reserved_special_token_211|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128017 '<|reserved_special_token_9|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128050 '<|reserved_special_token_42|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128205 '<|reserved_special_token_197|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128047 '<|reserved_special_token_39|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128164 '<|reserved_special_token_156|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128020 '<|reserved_special_token_12|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128069 '<|reserved_special_token_61|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128245 '<|reserved_special_token_237|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128121 '<|reserved_special_token_113|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128079 '<|reserved_special_token_71|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128037 '<|reserved_special_token_29|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128244 '<|reserved_special_token_236|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128029 '<|reserved_special_token_21|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128221 '<|reserved_special_token_213|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128066 '<|reserved_special_token_58|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128120 '<|reserved_special_token_112|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128014 '<|reserved_special_token_6|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128025 '<|reserved_special_token_17|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128126 '<|reserved_special_token_118|>' is not marked as EOG\n",
      "llm_load_vocab: special tokens cache size = 256\n",
      "llm_load_vocab: token to piece cache size = 0.7999 MB\n",
      "llm_load_print_meta: format           = GGUF V3 (latest)\n",
      "llm_load_print_meta: arch             = llama\n",
      "llm_load_print_meta: vocab type       = BPE\n",
      "llm_load_print_meta: n_vocab          = 128256\n",
      "llm_load_print_meta: n_merges         = 280147\n",
      "llm_load_print_meta: vocab_only       = 0\n",
      "llm_load_print_meta: n_ctx_train      = 131072\n",
      "llm_load_print_meta: n_embd           = 4096\n",
      "llm_load_print_meta: n_layer          = 32\n",
      "llm_load_print_meta: n_head           = 32\n",
      "llm_load_print_meta: n_head_kv        = 8\n",
      "llm_load_print_meta: n_rot            = 128\n",
      "llm_load_print_meta: n_swa            = 0\n",
      "llm_load_print_meta: n_embd_head_k    = 128\n",
      "llm_load_print_meta: n_embd_head_v    = 128\n",
      "llm_load_print_meta: n_gqa            = 4\n",
      "llm_load_print_meta: n_embd_k_gqa     = 1024\n",
      "llm_load_print_meta: n_embd_v_gqa     = 1024\n",
      "llm_load_print_meta: f_norm_eps       = 0.0e+00\n",
      "llm_load_print_meta: f_norm_rms_eps   = 1.0e-05\n",
      "llm_load_print_meta: f_clamp_kqv      = 0.0e+00\n",
      "llm_load_print_meta: f_max_alibi_bias = 0.0e+00\n",
      "llm_load_print_meta: f_logit_scale    = 0.0e+00\n",
      "llm_load_print_meta: n_ff             = 14336\n",
      "llm_load_print_meta: n_expert         = 0\n",
      "llm_load_print_meta: n_expert_used    = 0\n",
      "llm_load_print_meta: causal attn      = 1\n",
      "llm_load_print_meta: pooling type     = 0\n",
      "llm_load_print_meta: rope type        = 0\n",
      "llm_load_print_meta: rope scaling     = linear\n",
      "llm_load_print_meta: freq_base_train  = 500000.0\n",
      "llm_load_print_meta: freq_scale_train = 1\n",
      "llm_load_print_meta: n_ctx_orig_yarn  = 131072\n",
      "llm_load_print_meta: rope_finetuned   = unknown\n",
      "llm_load_print_meta: ssm_d_conv       = 0\n",
      "llm_load_print_meta: ssm_d_inner      = 0\n",
      "llm_load_print_meta: ssm_d_state      = 0\n",
      "llm_load_print_meta: ssm_dt_rank      = 0\n",
      "llm_load_print_meta: ssm_dt_b_c_rms   = 0\n",
      "llm_load_print_meta: model type       = 8B\n",
      "llm_load_print_meta: model ftype      = Q4_K - Medium\n",
      "llm_load_print_meta: model params     = 8.03 B\n",
      "llm_load_print_meta: model size       = 4.58 GiB (4.89 BPW) \n",
      "llm_load_print_meta: general.name     = Models\n",
      "llm_load_print_meta: BOS token        = 128000 '<|begin_of_text|>'\n",
      "llm_load_print_meta: EOS token        = 128009 '<|eot_id|>'\n",
      "llm_load_print_meta: EOT token        = 128009 '<|eot_id|>'\n",
      "llm_load_print_meta: EOM token        = 128008 '<|eom_id|>'\n",
      "llm_load_print_meta: LF token         = 128 'Ä'\n",
      "llm_load_print_meta: EOG token        = 128008 '<|eom_id|>'\n",
      "llm_load_print_meta: EOG token        = 128009 '<|eot_id|>'\n",
      "llm_load_print_meta: max token length = 256\n",
      "llm_load_tensors: tensor 'token_embd.weight' (q4_K) (and 290 others) cannot be used with preferred buffer type CPU_AARCH64, using CPU instead\n",
      "llm_load_tensors:   CPU_Mapped model buffer size =  4685.30 MiB\n",
      "........................................................................................\n",
      "llama_new_context_with_model: n_seq_max     = 1\n",
      "llama_new_context_with_model: n_ctx         = 128000\n",
      "llama_new_context_with_model: n_ctx_per_seq = 128000\n",
      "llama_new_context_with_model: n_batch       = 512\n",
      "llama_new_context_with_model: n_ubatch      = 512\n",
      "llama_new_context_with_model: flash_attn    = 0\n",
      "llama_new_context_with_model: freq_base     = 500000.0\n",
      "llama_new_context_with_model: freq_scale    = 1\n",
      "llama_new_context_with_model: n_ctx_per_seq (128000) < n_ctx_train (131072) -- the full capacity of the model will not be utilized\n",
      "llama_kv_cache_init:        CPU KV buffer size = 16000.00 MiB\n",
      "llama_new_context_with_model: KV self size  = 16000.00 MiB, K (f16): 8000.00 MiB, V (f16): 8000.00 MiB\n",
      "llama_new_context_with_model:        CPU  output buffer size =     0.49 MiB\n",
      "llama_new_context_with_model:        CPU compute buffer size =  8282.01 MiB\n",
      "llama_new_context_with_model: graph nodes  = 1030\n",
      "llama_new_context_with_model: graph splits = 1\n",
      "AVX = 1 | AVX_VNNI = 0 | AVX2 = 1 | AVX512 = 0 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | AVX512_BF16 = 0 | AMX_INT8 = 0 | FMA = 1 | NEON = 0 | SVE = 0 | ARM_FMA = 0 | F16C = 1 | FP16_VA = 0 | RISCV_VECT = 0 | WASM_SIMD = 0 | SSE3 = 1 | SSSE3 = 1 | VSX = 0 | MATMUL_INT8 = 0 | LLAMAFILE = 1 | \n",
      "Model metadata: {'tokenizer.chat_template': \"{% set loop_messages = messages %}{% for message in loop_messages %}{% set content = '<|start_header_id|>' + message['role'] + '<|end_header_id|>\\n\\n'+ message['content'] | trim + '<|eot_id|>' %}{% if loop.index0 == 0 %}{% set content = bos_token + content %}{% endif %}{{ content }}{% endfor %}{{ '<|start_header_id|>assistant<|end_header_id|>\\n\\n' }}\", 'tokenizer.ggml.eos_token_id': '128009', 'general.quantization_version': '2', 'tokenizer.ggml.model': 'gpt2', 'llama.rope.dimension_count': '128', 'llama.vocab_size': '128256', 'general.file_type': '15', 'general.architecture': 'llama', 'llama.rope.freq_base': '500000.000000', 'tokenizer.ggml.bos_token_id': '128000', 'llama.attention.head_count': '32', 'tokenizer.ggml.pre': 'smaug-bpe', 'llama.context_length': '131072', 'general.name': 'Models', 'general.type': 'model', 'general.size_label': '8.0B', 'general.license': 'llama3.1', 'llama.feed_forward_length': '14336', 'llama.attention.layer_norm_rms_epsilon': '0.000010', 'llama.embedding_length': '4096', 'llama.block_count': '32', 'llama.attention.head_count_kv': '8'}\n",
      "Available chat formats from metadata: chat_template.default\n",
      "Using gguf chat template: {% set loop_messages = messages %}{% for message in loop_messages %}{% set content = '<|start_header_id|>' + message['role'] + '<|end_header_id|>\n",
      "\n",
      "'+ message['content'] | trim + '<|eot_id|>' %}{% if loop.index0 == 0 %}{% set content = bos_token + content %}{% endif %}{{ content }}{% endfor %}{{ '<|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "' }}\n",
      "Using chat eos_token: <|eot_id|>\n",
      "Using chat bos_token: <|begin_of_text|>\n"
     ]
    }
   ],
   "source": [
    "llm = Llama.from_pretrained(\n",
    "    repo_id=\"QuantFactory/Meta-Llama-3.1-8B-Instruct-GGUF\",\n",
    "    filename=\"*Q4_K_M.gguf\",\n",
    "    # n_gpu_layers=-1,\n",
    "    n_ctx=128000,\n",
    "    verbose=True,\n",
    "    cache_dir=\"/checkpoint/lfy/14024697\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ask_food_prompt_template = \"The user is living in {user_location}. The user is looking for a {user_query}. Suggest 5 {user_query} which can be cooked by the user, without actual recipe.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_location = \"California\"\n",
    "user_query = \"vegan korean food\"\n",
    "ask_food_prompt = ask_food_prompt_template.format(user_location=user_location, user_query=user_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema_food_name = r'''\n",
    "root ::= (\n",
    "    \"{\" newline\n",
    "        doublespace \"\\\"food_names\\\":\" space listofstring newline\n",
    "    \"}\"\n",
    ")\n",
    "newline ::= \"\\n\"\n",
    "doublespace ::= \"  \"\n",
    "number ::= [0-9]+   \".\"?   [0-9]*\n",
    "boolean ::= \"true\" | \"false\"\n",
    "char ::= [^\"\\\\\\x7F\\x00-\\x1F] | [\\\\] ([\"\\\\bfnrt] | \"u\" [0-9a-fA-F]{4})\n",
    "space ::= | \" \" | \"\\n\" [ \\t]{0,20}\n",
    "string ::= \"\\\"\" char* \"\\\"\" space\n",
    "listofstring ::= (\"[\" space (string (\",\" space string){4})? \"]\")\n",
    "'''\n",
    "\n",
    "# Creating a LlamaGrammar object with schema string\n",
    "# Set verbose=False to not print the grammar, set to True for debugging\n",
    "grammar_food_name = LlamaGrammar.from_string(grammar=schema_food_name, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =     787.70 ms\n",
      "llama_perf_context_print: prompt eval time =       0.00 ms /    63 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /    70 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    7069.70 ms /   133 tokens\n"
     ]
    }
   ],
   "source": [
    "result = llm.create_chat_completion(\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"You are a helpful assistant that outputs in JSON.\",\n",
    "        },\n",
    "        {\"role\": \"user\", \"content\": ask_food_prompt},\n",
    "    ],\n",
    "    grammar=grammar_food_name,\n",
    "    temperature=0.7,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'food_names': ['Vegan Bibimbap',\n",
       "  'Korean-Style BBQ Jackfruit',\n",
       "  'Vegan Japchae (Stir-Fried Glass Noodles)',\n",
       "  'Kimchi Stew (Kimchi Jjigae)',\n",
       "  'Vegan Bulgogi (Marinated Vegan Beef)']}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_json = json.loads(result['choices'][0]['message']['content'])\n",
    "result_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_res = [{\"index\":0,\"query\":\"kimichi stew\",\"Name\":\"Perfect Chicken Stew\",\"RecipeInstructions\":\"c(\\\"Season a 3-7 pound chicken with Garlic powder and Pepper. Roast chicken in oven at 325 degrees.\\\", \\\"While chicken is cooking, dice potatoes, slice carrots, chop onions and carrots to desired thickness. Place vegetables in stewing pot and add water until vegetables are covered with about an 3 inches of water. Boil rapidly until potatoes are just finished.\\\", \\\"Remove vegetables from the pot by straining them and keep the water. By removing the vegetables and letting them cool, you prevent overcooking them and they won't dissolve into nothing.\\\", \\n\\\"With remaining water on low heat, add can of cream of mushroom soup, can of chicken stock and milk (milk optional, Zie Ga Zink).\\\", \\\"If you don't use milk, I suggest a premium ready to serve brand of creamed mushroom soup, it will be of a smoother, creamier consistency than the regular cans of mushroom soup.\\\", \\\"Get a small sealable container and fill with 1 cup of cold water, then add 1 cup of flour, cover and seal, then immediately shake vigorously. You are making a thickener for the stew, it should look like the consistency of glue with no lumps. If to thick add a bit of water, too thin add a bit more flour, shake very hard again. If there are a few lumps you can remove them by straining. This process, once learned, is very useful for making gravies or other stews without using a high-fat butter and flour 'roux' thickener.\\\", \\n\\\"Rapidly add thickener to the starch water/mushroom soup/stock/milk mixture using a whisk. You may have to make a little more thickener if you want a hardier stew, just remember that the stew will thicken more after it is removed from the heat and it stands. Simmer to desired consistency. Stir often. Do not burn! I suggest a non-stick stew pot, it helps prevent burning.\\\", \\\"Add the cooked (now cooled) vegetables to the stew.\\\", \\\"When chicken is finished roasting, drain juices into the stew. Remove skin and bones.  Tear or cut chicken apart and add to the stew.\\\", \\n\\\"Stir in about 2-3 tablespoons of salt to stew  and about the same amount of pepper to taste.\\\", \\\"If you want, try adding a dash of hot sauce or a pinch of Sambel Olek.\\\", \\\"Let stew simmer for a little longer. Serve with fresh bread and Enjoy.\\\", \\\"Questions? brennarlauterbach@hotmail.com.\\\")\"},{\"index\":1,\"query\":\"kimichi stew\",\"Name\":\"Wintry Beef Vegetable Stew With Fluffy Herb Dumplings\",\"RecipeInstructions\":\"c(\\\"Cook and stir beef in shortening in heavy 8-10 quart stock pot, until beef is well browned. (Note: If too much liquid builds up to prevent adequate browning, pour off excess liquid into a bowl and reserve. Continue to brown the beef and when well browned, add the reserved liquid back into the pot.).\\\", \\\"Add 5 cups hot water, 1/2 teaspoon salt and the black pepper.\\\", \\\"Heat to boiling; reduce heat.\\\", \\\"Cover and simmer until beef is almost tender, 45 minutes to 1 hour.\\\", \\\"Stir in potato, turnip, rutabaga, carrots, green pepper, green beans (if using), celery, onion, bouquet sauce, the bouillon cube and bay leaves.\\\", \\n\\\"Cover and simmer until vegetables are tender (but do not overcook), stirring once, about 25 minutes.\\\", \\\"Prepare dough (see below) for Dumplings;  set aside.\\\", \\\"Using a fork, blend together 1 cup cold water and the 4 tablespoons flour in a small mixing bowl; stir gradually into stew.\\\", \\\"Heat to boiling, stirring constantly.\\\", \\\"Boil and stir 1 minute; reduce heat.\\\", \\\"Do ahead tip: After boiling and stirring 1 minute, stew can be covered and refrigerated no longer than 48 hours. To serve, heat to boiling over medium-high heat. Continue as directed.\\\", \\n\\\"DUMPLINGS:\\\", \\\"In a large bowl, cut shortening into combined flour, baking powder, salt, parsley and herbs until mixture resembles fine crumbs.\\\", \\\"Stir in milk.\\\", \\\"Drop by heaping tablespoons onto hot meat or vegetables in boiling stew (do not drop directly into liquid).\\\", \\\"Cook uncovered 15 minutes.\\\", \\\"Cover and cook about 15 minutes longer. Cut a dumpling in half to test for doneness; you want them done but not dry!\\\", \\\"Serve stew piping hot, with a buttered baguette and a glass of cider, ale, or wine. As with all good stews, this stew is even better reheated the next day, after flavors have had a chance to meld. Stew leftovers freeze and reheat beautifully, and would make a delicious cottage or shepherd's pie.\\\"\\n)\"}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "extracted_recipe = {}\n",
    "for recipe in query_res:\n",
    "    recipe_name = recipe['Name']\n",
    "    recipe_instructions = recipe[\"RecipeInstructions\"]\n",
    "    matches = re.findall(r'\"(.*?)\"', recipe_instructions)\n",
    "    recipe_instructions = tuple(matches)\n",
    "    steps_dict = {f\"Step {i+1}\": step for i, step in enumerate(recipe_instructions)}\n",
    "    steps_json = json.dumps(steps_dict, indent=2)\n",
    "    extracted_recipe[recipe_name] = {} # Overwrite recipe with same name, no duplicate\n",
    "    extracted_recipe[recipe_name]['instructions'] = steps_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "ask_recipe_template = \"The user is living in {user_location}. The user is looking for a {user_query}. Here are few potential recipes: {retrieved_recipes}. Based on such recipe, generate a new recipe that satisfy user nutrition requirements. You can reuse the existing recipe, or you can modify it or create a new recipe.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "ask_recipe_prompt = ask_recipe_template.format(user_location=user_location, user_query=user_query, retrieved_recipes=extracted_recipe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# schema_recipe = r'''\n",
    "# root ::= (\n",
    "#     \"{\" newline\n",
    "#         doublespace \"\\\"Description\\\":\" space string \",\" newline\n",
    "#         doublespace \"\\\"Cooking instructions\\\":\" cookinstructs \",\" space \n",
    "#         # doublespace \"\\\"Ingredients\\\":\" space ingreds newline\n",
    "#     \"}\"\n",
    "# )\n",
    "# newline ::= \"\\n\"\n",
    "# doublespace ::= \"  \"\n",
    "# number ::= [0-9]+   \".\"?   [0-9]*\n",
    "# integer ::= [0-9]*\n",
    "# boolean ::= \"true\" | \"false\"\n",
    "# char ::= [^\"\\\\\\x7F\\x00-\\x1F] | [\\\\] ([\"\\\\bfnrt] | \"u\" [0-9a-fA-F]{4})\n",
    "# space ::= | \" \" | \"\\n\" [ \\t]{0,20}\n",
    "# string ::= \"\\\"\" char* \"\\\"\" space\n",
    "# sentence ::= char* space\n",
    "# listofstring ::= (\"[\" space (string (\",\" space string)*)? \"]\")\n",
    "# cookstep ::= (\"\\\"Step\" space integer \"\\\"\" \":\" space string)\n",
    "# cookinstructs ::= (space \"{\" space (cookstep (\",\" space cookstep){20})? \"}\")\n",
    "# ingred ::= (\"{\" space \"\\\"Ingredient\\\":\" space string \", \\\"Unit\\\": \" string \", \\\"Amount\\\": \" number \"}\")\n",
    "# ingreds ::= (space \"\\[\" space (ingred (\",\" space ingred){0,30}) \"\\]\")\n",
    "# '''\n",
    "\n",
    "\n",
    "schema_recipe = r'''\n",
    "root ::= (\n",
    "    \"{\" newline\n",
    "        doublespace \"\\\"Description\\\":\" space string \",\" newline\n",
    "        doublespace \"\\\"Cooking instructions\\\":\" cookinstructs space \n",
    "    \"}\"\n",
    ")\n",
    "newline ::= \"\\n\"\n",
    "doublespace ::= \"  \"\n",
    "number ::= [0-9]+   \".\"?   [0-9]*\n",
    "integer ::= [0-9]*\n",
    "boolean ::= \"true\" | \"false\"\n",
    "char ::= [^\"\\\\\\x7F\\x00-\\x1F] | [\\\\] ([\"\\\\bfnrt] | \"u\" [0-9a-fA-F]{4})\n",
    "space ::= | \" \" | \"\\n\" [ \\t]{0,20}\n",
    "string ::= \"\\\"\" char* \"\\\"\" space\n",
    "sentence ::= char* space\n",
    "listofstring ::= (\"[\" space (string (\",\" space string)*)? \"]\")\n",
    "cookstep ::= (\"\\\"Step\" space integer \"\\\"\" \":\" space string)\n",
    "cookinstructs ::= (space \"{\" space (cookstep (\",\" space cookstep){10})? \"}\")\n",
    "'''\n",
    "\n",
    "grammar_recipe = LlamaGrammar.from_string(grammar=schema_recipe, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: 15 prefix-match hit, remaining 1404 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =     787.70 ms\n",
      "llama_perf_context_print: prompt eval time =       0.00 ms /  1404 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /   396 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =   61289.88 ms /  1800 tokens\n"
     ]
    }
   ],
   "source": [
    "result = llm.create_chat_completion(\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"You are a helpful assistant that outputs in JSON. You must not include nutrition information or any notes. Stop generating instructions when the food is ready to serve. Do not put notes or nutrition in cooking instructions. Your output will be in the format: {\\\"Description\\\": A brief description of the recipe, \\\"Cooking Instructions\\\": {\\\"Step 1\\\": first cooking step, \\\"Step 2\\\": second cooking step, ...}}\",\n",
    "        },\n",
    "        {\"role\": \"user\", \"content\": ask_recipe_prompt},\n",
    "    ],\n",
    "    grammar=grammar_recipe,\n",
    "    temperature=0.7,\n",
    "    # stream=True\n",
    ")\n",
    "\n",
    "# for chunk in result:\n",
    "#     delta = chunk['choices'][0]['delta']\n",
    "#     if 'role' in delta:\n",
    "#         print(delta['role'], end=': ')\n",
    "#     elif 'content' in delta:\n",
    "#         print(delta['content'], end='')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"Description\": \"Vegan Korean-Style Stew\",\n",
      "  \"Cooking instructions\": {\n",
      "    \"Step 1\": \"Cook and stir vegan beef strips in a little oil in a large pot until browned. Add 5 cups of vegetable broth, 1/2 teaspoon of salt, and the black pepper. Heat to boiling; reduce heat.\",\n",
      "    \"Step 2\": \"Add 1 cup of diced Korean chili flakes (gochugaru), 1 cup of diced carrots, 1 cup of diced zucchini, 1 cup of diced bell peppers, and 1 cup of diced mushrooms. Simmer until the vegetables are tender.\",\n",
      "    \"Step 3\": \"Prepare the Korean chili paste (gochujang) by mixing 2 tablespoons of gochujang with 2 tablespoons of soy sauce and 2 tablespoons of rice vinegar.\",\n",
      "    \"Step 4\": \"Add the gochujang mixture to the pot and stir to combine. Simmer for 10 minutes.\",\n",
      "    \"Step 5\": \"Serve the stew hot, garnished with green onions and crispy garlic. Enjoy!\"\n",
      "  \t\t\t\t\t\t\t \t,\"Step 6\": \"Optional: Serve with a side of steamed rice or noodles.\"\n",
      "  \t\t\t\t\t\t\t \t,\"Step 7\": \"Optional: Add some kimchi to the stew for an extra kick of flavor.\"\n",
      "  \t\t\t\t\t\t\t \t,\"Step 8\": \"Optional: Use different types of mushrooms or vegetables to change up the flavor and texture of the stew.\"\n",
      "  \t\t\t\t\t\t\t \t,\"Step 9\": \"Optional: Add some sesame oil or seeds to the stew for added flavor and nutrition.\"\n",
      "  \t\t\t\t\t\t\t \t,\"Step 10\": \"Optional: Use a slow cooker to cook the stew all day, perfect for a weeknight dinner.\"\n",
      "  \t\t\t\t\t\t\t\t,\"Step 11\": \"Optional: Make the stew in a Instant Pot for a quick and easy meal.\"\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(result['choices'][0]['message']['content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "cook_steps = json.loads(result['choices'][0]['message']['content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "concat_steps = cook_steps['Description']\n",
    "concat_steps += '\\n'\n",
    "\n",
    "for step in cook_steps['Cooking instructions']:\n",
    "    # concat_steps.append()\n",
    "    concat_steps += step\n",
    "    concat_steps += ': '\n",
    "    concat_steps += cook_steps['Cooking instructions'][step]\n",
    "    concat_steps += '\\n'\n",
    "concat_steps = concat_steps[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vegan Korean-Style Stew\n",
      "Step 1: Cook and stir vegan beef strips in a little oil in a large pot until browned. Add 5 cups of vegetable broth, 1/2 teaspoon of salt, and the black pepper. Heat to boiling; reduce heat.\n",
      "Step 2: Add 1 cup of diced Korean chili flakes (gochugaru), 1 cup of diced carrots, 1 cup of diced zucchini, 1 cup of diced bell peppers, and 1 cup of diced mushrooms. Simmer until the vegetables are tender.\n",
      "Step 3: Prepare the Korean chili paste (gochujang) by mixing 2 tablespoons of gochujang with 2 tablespoons of soy sauce and 2 tablespoons of rice vinegar.\n",
      "Step 4: Add the gochujang mixture to the pot and stir to combine. Simmer for 10 minutes.\n",
      "Step 5: Serve the stew hot, garnished with green onions and crispy garlic. Enjoy!\n",
      "Step 6: Optional: Serve with a side of steamed rice or noodles.\n",
      "Step 7: Optional: Add some kimchi to the stew for an extra kick of flavor.\n",
      "Step 8: Optional: Use different types of mushrooms or vegetables to change up the flavor and texture of the stew.\n",
      "Step 9: Optional: Add some sesame oil or seeds to the stew for added flavor and nutrition.\n",
      "Step 10: Optional: Use a slow cooker to cook the stew all day, perfect for a weeknight dinner.\n",
      "Step 11: Optional: Make the stew in a Instant Pot for a quick and easy meal.\n"
     ]
    }
   ],
   "source": [
    "print(concat_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "ask_ingreds_template = \"The user is living in {user_location}. The user is looking for a {user_query}. Here is a generated recipe: {generated_recipes}. Generate all ingredients with their corresponding unit and amount in the recipe. For each ingredient, list their name, and their weight in grams.\"\n",
    "\n",
    "ask_ingreds_prompt = ask_ingreds_template.format(user_location=user_location, user_query=user_query, generated_recipes=concat_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The user is living in California. The user is looking for a vegan korean food. Here is a generated recipe: Vegan Korean-Style Stew\n",
      "Step 1: Cook and stir vegan beef strips in a little oil in a large pot until browned. Add 5 cups of vegetable broth, 1/2 teaspoon of salt, and the black pepper. Heat to boiling; reduce heat.\n",
      "Step 2: Add 1 cup of diced Korean chili flakes (gochugaru), 1 cup of diced carrots, 1 cup of diced zucchini, 1 cup of diced bell peppers, and 1 cup of diced mushrooms. Simmer until the vegetables are tender.\n",
      "Step 3: Prepare the Korean chili paste (gochujang) by mixing 2 tablespoons of gochujang with 2 tablespoons of soy sauce and 2 tablespoons of rice vinegar.\n",
      "Step 4: Add the gochujang mixture to the pot and stir to combine. Simmer for 10 minutes.\n",
      "Step 5: Serve the stew hot, garnished with green onions and crispy garlic. Enjoy!\n",
      "Step 6: Optional: Serve with a side of steamed rice or noodles.\n",
      "Step 7: Optional: Add some kimchi to the stew for an extra kick of flavor.\n",
      "Step 8: Optional: Use different types of mushrooms or vegetables to change up the flavor and texture of the stew.\n",
      "Step 9: Optional: Add some sesame oil or seeds to the stew for added flavor and nutrition.\n",
      "Step 10: Optional: Use a slow cooker to cook the stew all day, perfect for a weeknight dinner.\n",
      "Step 11: Optional: Make the stew in a Instant Pot for a quick and easy meal.. Generate all ingredients with their corresponding unit and amount in the recipe. For each ingredient, list their name, and their weight in grams.\n"
     ]
    }
   ],
   "source": [
    "print(ask_ingreds_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: 404 prefix-match hit, remaining 19 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =     787.70 ms\n",
      "llama_perf_context_print: prompt eval time =       0.00 ms /    19 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /   366 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =   39242.54 ms /   385 tokens\n"
     ]
    }
   ],
   "source": [
    "schema_recipe = r'''\n",
    "root ::= (\n",
    "    \"{\" newline\n",
    "        doublespace \"\\\"Ingredients\\\":\" space ingreds newline\n",
    "    \"}\"\n",
    ")\n",
    "newline ::= \"\\n\"\n",
    "doublespace ::= \"  \"\n",
    "number ::= [0-9]+   \".\"?   [0-9]*\n",
    "integer ::= [0-9]*\n",
    "boolean ::= \"true\" | \"false\"\n",
    "char ::= [^\"\\\\\\x7F\\x00-\\x1F] | [\\\\] ([\"\\\\bfnrt] | \"u\" [0-9a-fA-F]{4})\n",
    "space ::= | \" \" | \"\\n\" [ \\t]{0,20}\n",
    "string ::= \"\\\"\" char* \"\\\"\" space\n",
    "sentence ::= char* space\n",
    "listofstring ::= (\"[\" space (string (\",\" space string)*)? \"]\")\n",
    "cookstep ::= (\"\\\"Step\" space integer \"\\\"\" \":\" space string)\n",
    "cookinstructs ::= (space \"{\" space (cookstep (\",\" space cookstep){10})? \"}\")\n",
    "ingredname ::= (\"\\\"Ingredient name\" space \"\\\"\" \":\" space string)\n",
    "ingredunit ::= (\"\\\"Unit\" space \"\\\"\" \":\" space string)\n",
    "ingredamt ::= (\"\\\"Amount\" space \"\\\"\" \":\" space number)\n",
    "ingredwgt ::= (\"\\\"Grams\" space \"\\\"\" \":\" space number)\n",
    "ingredset ::= (\"{\" ingredname \",\" space ingredwgt space \"}\")\n",
    "ingreds ::= (space \"[\" space (ingredset (\",\" space ingredset){20})? \"]\")\n",
    "'''\n",
    "\n",
    "grammar_recipe = LlamaGrammar.from_string(grammar=schema_recipe, verbose=False)\n",
    "\n",
    "\n",
    "result = llm.create_chat_completion(\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"You are a helpful assistant that outputs in JSON. You must not include nutrition information or any notes. Do not put notes or nutrition in cooking instructions.\",\n",
    "        },\n",
    "        {\"role\": \"user\", \"content\": ask_ingreds_prompt},\n",
    "    ],\n",
    "    grammar=grammar_recipe,\n",
    "    temperature=0.7,\n",
    "    # stream=True\n",
    ")\n",
    "\n",
    "# for chunk in result:\n",
    "#     delta = chunk['choices'][0]['delta']\n",
    "#     if 'role' in delta:\n",
    "#         print(delta['role'], end=': ')\n",
    "#     elif 'content' in delta:\n",
    "#         print(delta['content'], end='')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "ingreds = json.loads(result['choices'][0]['message']['content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'Ingredient name': 'Vegan beef strips', 'Grams': 200},\n",
       " {'Ingredient name': 'Oil', 'Grams': 30},\n",
       " {'Ingredient name': 'Vegetable broth', 'Grams': 1100},\n",
       " {'Ingredient name': 'Salt', 'Grams': 6},\n",
       " {'Ingredient name': 'Black pepper', 'Grams': 3},\n",
       " {'Ingredient name': 'Korean chili flakes (gochugaru)', 'Grams': 450},\n",
       " {'Ingredient name': 'Carrots', 'Grams': 250},\n",
       " {'Ingredient name': 'Zucchini', 'Grams': 250},\n",
       " {'Ingredient name': 'Bell peppers', 'Grams': 250},\n",
       " {'Ingredient name': 'Mushrooms', 'Grams': 250},\n",
       " {'Ingredient name': 'Gochujang', 'Grams': 120},\n",
       " {'Ingredient name': 'Soy sauce', 'Grams': 60},\n",
       " {'Ingredient name': 'Rice vinegar', 'Grams': 60},\n",
       " {'Ingredient name': 'Green onions', 'Grams': 30},\n",
       " {'Ingredient name': 'Crispy garlic', 'Grams': 30},\n",
       " {'Ingredient name': 'Sesame oil', 'Grams': 15},\n",
       " {'Ingredient name': 'Sesame seeds', 'Grams': 15},\n",
       " {'Ingredient name': 'Kimchi', 'Grams': 150},\n",
       " {'Ingredient name': 'Steamed rice', 'Grams': 200},\n",
       " {'Ingredient name': 'Noodles', 'Grams': 200},\n",
       " {'Ingredient name': 'Rice', 'Grams': 200}]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ingreds['Ingredients']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Amount'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[33], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m ingreds_concat \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m ing[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mIngredient name\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m      4\u001b[0m ingreds_concat \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m----> 5\u001b[0m ingreds_concat \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(\u001b[43ming\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mAmount\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m)\n\u001b[1;32m      6\u001b[0m ingreds_concat \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m      7\u001b[0m ingreds_concat \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m ing[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUnit\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Amount'"
     ]
    }
   ],
   "source": [
    "ingreds_concat = \"\"\n",
    "for ing in ingreds['Ingredients']:\n",
    "    ingreds_concat += ing['Ingredient name']\n",
    "    ingreds_concat += ' '\n",
    "    ingreds_concat += str(ing['Amount'])\n",
    "    ingreds_concat += ' '\n",
    "    ingreds_concat += ing['Unit']\n",
    "    ingreds_concat += '.\\n'\n",
    "print(ingreds_concat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/fs01/home/lfy/attribution/context-attribution/contatt/lib/python3.10/site-packages/fuzzywuzzy/fuzz.py:11: UserWarning: Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning\n",
      "  warnings.warn('Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning')\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "from fuzzywuzzy import process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fuzzywuzzy import process\n",
    "# Function to get the best match from df2 for each ingredient\n",
    "def get_best_match(ingredient, choices, threshold=80):\n",
    "    best_match, score = process.extractOne(ingredient, choices)\n",
    "    if score >= threshold:\n",
    "        return best_match\n",
    "    return None  # If no good match is found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of recipes with missing info: 1590\n",
      "Missing values per column:\n",
      "saturated_fat    1590\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df_nutritions = pd.read_csv(\"nutrition.csv\")\n",
    "num_nutrition_with_missing_info = df_nutritions.isnull().any(axis=1).sum()\n",
    "print(f\"Number of recipes with missing info: {num_nutrition_with_missing_info}\")\n",
    "missing_per_column_nutrition = df_nutritions.isnull().sum()\n",
    "missing_per_column_nutrition = missing_per_column_nutrition[missing_per_column_nutrition > 0]\n",
    "print(f\"Missing values per column:\\n{missing_per_column_nutrition}\")\n",
    "df_nutritions.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "important_nutrients = ['calories', 'total_fat', 'fat', 'saturated_fat', 'saturated_fatty_acids', 'cholesterol',\n",
    " 'sodium', 'carbohydrate', 'fiber', 'sugars', 'protein', 'vitamin_a', 'vitamin_a_rae',\n",
    " 'carotene_alpha', 'carotene_beta', 'cryptoxanthin_beta', 'lutein_zeaxanthin', 'lucopene',\n",
    " 'vitamin_b12', 'vitamin_b6', 'vitamin_c', 'vitamin_d', 'vitamin_e', 'tocopherol_alpha',\n",
    " 'vitamin_k', 'calcium', 'copper', 'iron', 'magnesium', 'manganese', 'phosphorous',\n",
    " 'potassium', 'selenium', 'zinc', 'water']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_best_match(ingredients, df, important_nutrients, threshold=80):\n",
    "    choices = df['name'].tolist()\n",
    "\n",
    "    result = []\n",
    "    for ingredient in ingredients:\n",
    "        best_match, score = process.extractOne(ingredient['Ingredient name'], choices)\n",
    "\n",
    "        # if the score doesn't reach threshold, there is no valid match found for ingredient\n",
    "        if score < threshold:\n",
    "            print(f\"No valid match found for {ingredient['Ingredient name']}\")\n",
    "            # put 0 for all important nutrients\n",
    "            for important_nutrient in important_nutrients:\n",
    "                ingredient[important_nutrient] = 0\n",
    "            result.append(ingredient)\n",
    "            continue\n",
    "\n",
    "        # combine the columns in df['name'] == best_match to key and value pairs in the dictionary\n",
    "        # only add the key and value pairs where key exists in important_nutrients\n",
    "        best_match_row = df[df['name'] == best_match].to_dict('records')[0]\n",
    "        for key, value in best_match_row.items():\n",
    "            if key in important_nutrients:\n",
    "\n",
    "                if isinstance(value, str):  # If the value is a string, check for units\n",
    "                    # Use regular expression to remove units like 'g', 'mg', 'IU', etc.\n",
    "                    cleaned_value = re.sub(r'[^\\d.-]', '', value)  # Remove anything that's not a digit or decimal point\n",
    "                    # add value to ingredient\n",
    "                    ingredient[key] = float(cleaned_value) * float(ingredient['Grams']) / 100 if cleaned_value else 0.0\n",
    "\n",
    "        result.append(ingredient)\n",
    "\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Ingredient name': 'Vegan beef strips', 'Grams': 200}\n",
      "{'Ingredient name': 'Oil', 'Grams': 30}\n",
      "{'Ingredient name': 'Vegetable broth', 'Grams': 1100}\n",
      "{'Ingredient name': 'Salt', 'Grams': 6}\n",
      "{'Ingredient name': 'Black pepper', 'Grams': 3}\n",
      "{'Ingredient name': 'Korean chili flakes (gochugaru)', 'Grams': 450}\n",
      "{'Ingredient name': 'Carrots', 'Grams': 250}\n",
      "{'Ingredient name': 'Zucchini', 'Grams': 250}\n",
      "{'Ingredient name': 'Bell peppers', 'Grams': 250}\n",
      "{'Ingredient name': 'Mushrooms', 'Grams': 250}\n",
      "{'Ingredient name': 'Gochujang', 'Grams': 120}\n",
      "No valid match found for Gochujang\n",
      "{'Ingredient name': 'Soy sauce', 'Grams': 60}\n",
      "{'Ingredient name': 'Rice vinegar', 'Grams': 60}\n",
      "{'Ingredient name': 'Green onions', 'Grams': 30}\n",
      "{'Ingredient name': 'Crispy garlic', 'Grams': 30}\n",
      "{'Ingredient name': 'Sesame oil', 'Grams': 15}\n",
      "{'Ingredient name': 'Sesame seeds', 'Grams': 15}\n",
      "{'Ingredient name': 'Kimchi', 'Grams': 150}\n",
      "{'Ingredient name': 'Steamed rice', 'Grams': 200}\n",
      "{'Ingredient name': 'Noodles', 'Grams': 200}\n",
      "{'Ingredient name': 'Rice', 'Grams': 200}\n",
      "{'Ingredient name': 'Vegan beef strips', 'Grams': 200, 'total_fat': 52.0, 'saturated_fat': 18.6, 'cholesterol': 178.0, 'sodium': 3480.0, 'vitamin_a': 0.0, 'vitamin_a_rae': 0.0, 'carotene_alpha': 0.0, 'carotene_beta': 0.0, 'cryptoxanthin_beta': 0.0, 'lutein_zeaxanthin': 0.0, 'vitamin_b12': 3.04, 'vitamin_b6': 0.9179999999999999, 'vitamin_c': 0.0, 'vitamin_d': 82.0, 'vitamin_e': 0.44, 'tocopherol_alpha': 0.44, 'vitamin_k': 6.4, 'calcium': 30.0, 'copper': 0.714, 'magnesium': 38.0, 'manganese': 1.956, 'phosphorous': 382.0, 'potassium': 632.0, 'selenium': 62.6, 'protein': 43.7, 'carbohydrate': 4.8, 'fiber': 0.0, 'sugars': 1.92, 'fat': 51.8, 'saturated_fatty_acids': 18.632, 'water': 90.38}\n",
      "{'Ingredient name': 'Oil', 'Grams': 30, 'total_fat': 4.5, 'saturated_fat': 1.17, 'cholesterol': 25.2, 'sodium': 20.1, 'vitamin_a': 30.0, 'vitamin_a_rae': 9.0, 'carotene_alpha': 0.0, 'carotene_beta': 0.0, 'cryptoxanthin_beta': 0.0, 'lutein_zeaxanthin': 0.0, 'vitamin_b12': 0.141, 'vitamin_b6': 0.003, 'vitamin_c': 0.0, 'vitamin_d': 2.4, 'vitamin_e': 0.08100000000000002, 'tocopherol_alpha': 0.08100000000000002, 'vitamin_k': 0.06, 'calcium': 26.4, 'copper': 0.030599999999999995, 'magnesium': 1.5, 'manganese': 0.0, 'phosphorous': 24.9, 'potassium': 9.3, 'selenium': 1.08, 'protein': 5.82, 'carbohydrate': 0.06, 'fiber': 0.0, 'sugars': 0.0, 'fat': 4.38, 'saturated_fatty_acids': 1.176, 'water': 19.74}\n",
      "{'Ingredient name': 'Vegetable broth', 'Grams': 1100, 'total_fat': 1.1, 'cholesterol': 0.0, 'sodium': 3333.0, 'vitamin_a': 3179.0, 'vitamin_a_rae': 154.0, 'carotene_alpha': 825.0, 'carotene_beta': 1496.0, 'cryptoxanthin_beta': 0.0, 'lutein_zeaxanthin': 11.0, 'vitamin_b12': 0.0, 'vitamin_b6': 0.077, 'vitamin_c': 4.4, 'vitamin_d': 0.0, 'vitamin_e': 0.0, 'tocopherol_alpha': 0.0, 'vitamin_k': 0.0, 'calcium': 33.0, 'copper': 0.09899999999999999, 'magnesium': 11.0, 'manganese': 0.055, 'phosphorous': 33.0, 'potassium': 220.0, 'selenium': 0.0, 'protein': 2.53, 'carbohydrate': 11.22, 'fiber': 0.0, 'sugars': 6.27, 'fat': 0.7700000000000001, 'saturated_fatty_acids': 0.341, 'water': 1077.12}\n",
      "{'Ingredient name': 'Salt', 'Grams': 6, 'total_fat': 4.86, 'saturated_fat': 3.0, 'cholesterol': 12.9, 'sodium': 0.66, 'vitamin_a': 149.94, 'vitamin_a_rae': 41.04, 'carotene_alpha': 0.0, 'carotene_beta': 9.48, 'cryptoxanthin_beta': 0.0, 'lutein_zeaxanthin': 0.0, 'vitamin_b12': 0.0102, 'vitamin_b6': 0.00018, 'vitamin_c': 0.0, 'vitamin_d': 0.0, 'vitamin_e': 0.1392, 'tocopherol_alpha': 0.1392, 'vitamin_k': 0.42, 'calcium': 1.44, 'copper': 0.00096, 'magnesium': 0.12, 'manganese': 0.00024, 'phosphorous': 1.44, 'potassium': 1.44, 'selenium': 0.06, 'protein': 0.051, 'carbohydrate': 0.0036, 'fiber': 0.0, 'sugars': 0.0036, 'fat': 4.8666, 'saturated_fatty_acids': 3.0293399999999995, 'water': 1.0764000000000002}\n",
      "{'Ingredient name': 'Black pepper', 'Grams': 3, 'total_fat': 0.09899999999999999, 'saturated_fat': 0.041999999999999996, 'cholesterol': 0.0, 'sodium': 0.6, 'vitamin_a': 16.41, 'vitamin_a_rae': 0.81, 'carotene_alpha': 0.36, 'carotene_beta': 9.3, 'cryptoxanthin_beta': 0.75, 'lutein_zeaxanthin': 13.62, 'vitamin_b12': 0.0, 'vitamin_b6': 0.00873, 'vitamin_c': 0.0, 'vitamin_d': 0.0, 'vitamin_e': 0.031200000000000002, 'tocopherol_alpha': 0.031200000000000002, 'vitamin_k': 4.911, 'calcium': 13.29, 'copper': 0.039900000000000005, 'magnesium': 5.13, 'manganese': 0.38259, 'phosphorous': 4.74, 'potassium': 39.87, 'selenium': 0.14700000000000002, 'protein': 0.31170000000000003, 'carbohydrate': 1.9185000000000003, 'fiber': 0.759, 'sugars': 0.0192, 'fat': 0.0978, 'saturated_fatty_acids': 0.04176, 'water': 0.3738}\n",
      "{'Ingredient name': 'Korean chili flakes (gochugaru)', 'Grams': 450, 'total_fat': 63.0, 'saturated_fat': 11.25, 'cholesterol': 0.0, 'sodium': 12901.5, 'vitamin_a': 133425.0, 'vitamin_a_rae': 6673.5, 'carotene_alpha': 9405.0, 'carotene_beta': 67500.0, 'cryptoxanthin_beta': 15705.0, 'lutein_zeaxanthin': 1395.0, 'vitamin_b12': 0.0, 'vitamin_b6': 9.423, 'vitamin_c': 3.15, 'vitamin_d': 0.0, 'vitamin_e': 171.63, 'tocopherol_alpha': 171.63, 'vitamin_k': 475.65, 'calcium': 1485.0, 'copper': 4.5, 'magnesium': 670.5, 'manganese': 7.65, 'phosphorous': 1350.0, 'potassium': 8775.0, 'selenium': 91.8, 'protein': 60.57, 'carbohydrate': 223.65, 'fiber': 156.6, 'sugars': 32.355, 'fat': 64.26, 'saturated_fatty_acids': 11.079, 'water': 48.375}\n",
      "{'Ingredient name': 'Carrots', 'Grams': 250, 'total_fat': 0.25, 'cholesterol': 0.0, 'sodium': 195.0, 'vitamin_a': 34475.0, 'vitamin_a_rae': 1725.0, 'carotene_alpha': 9417.5, 'carotene_beta': 15977.5, 'cryptoxanthin_beta': 0.0, 'lutein_zeaxanthin': 895.0, 'vitamin_b12': 0.0, 'vitamin_b6': 0.2625, 'vitamin_c': 6.5, 'vitamin_d': 0.0, 'vitamin_e': 0.0, 'tocopherol_alpha': 0.0, 'vitamin_k': 23.5, 'calcium': 80.0, 'copper': 0.25, 'magnesium': 25.0, 'manganese': 0.3775, 'phosphorous': 70.0, 'potassium': 592.5, 'selenium': 2.25, 'protein': 1.6, 'carbohydrate': 20.6, 'fiber': 7.25, 'sugars': 11.9, 'fat': 0.325, 'saturated_fatty_acids': 0.0575, 'water': 225.875}\n",
      "{'Ingredient name': 'Zucchini', 'Grams': 250, 'total_fat': 1.0, 'saturated_fat': 0.25, 'cholesterol': 0.0, 'sodium': 7.5, 'vitamin_a': 1225.0, 'vitamin_a_rae': 62.5, 'carotene_alpha': 0.0, 'carotene_beta': 0.0, 'cryptoxanthin_beta': 0.0, 'lutein_zeaxanthin': 0.0, 'vitamin_b12': 0.0, 'vitamin_b6': 0.355, 'vitamin_c': 85.25, 'vitamin_d': 0.0, 'vitamin_e': 0.0, 'tocopherol_alpha': 0.0, 'vitamin_k': 0.0, 'calcium': 52.5, 'copper': 0.2425, 'magnesium': 82.5, 'manganese': 0.49, 'phosphorous': 232.5, 'potassium': 1147.5, 'selenium': 0.75, 'protein': 6.775, 'carbohydrate': 7.775, 'fiber': 2.75, 'sugars': 0.0, 'fat': 1.0, 'saturated_fatty_acids': 0.2075, 'water': 231.825}\n",
      "{'Ingredient name': 'Bell peppers', 'Grams': 250, 'total_fat': 1.0, 'saturated_fat': 0.25, 'cholesterol': 0.0, 'sodium': 7.5, 'vitamin_a': 2695.0, 'vitamin_a_rae': 135.0, 'carotene_alpha': 167.5, 'carotene_beta': 1402.5, 'cryptoxanthin_beta': 262.5, 'lutein_zeaxanthin': 2152.5, 'vitamin_b12': 0.0, 'vitamin_b6': 1.0475, 'vitamin_c': 296.5, 'vitamin_d': 0.0, 'vitamin_e': 8.95, 'tocopherol_alpha': 8.95, 'vitamin_k': 46.25, 'calcium': 30.0, 'copper': 0.115, 'magnesium': 37.5, 'manganese': 0.2425, 'phosphorous': 65.0, 'potassium': 620.0, 'selenium': 1.0, 'protein': 2.275, 'carbohydrate': 16.25, 'fiber': 7.0, 'sugars': 10.3, 'fat': 0.925, 'saturated_fatty_acids': 0.23, 'water': 229.225}\n",
      "{'Ingredient name': 'Mushrooms', 'Grams': 250, 'total_fat': 0.75, 'cholesterol': 0.0, 'sodium': 7.5, 'vitamin_a': 0.0, 'vitamin_a_rae': 0.0, 'carotene_alpha': 0.0, 'carotene_beta': 0.0, 'cryptoxanthin_beta': 0.0, 'lutein_zeaxanthin': 0.0, 'vitamin_b12': 0.0, 'vitamin_b6': 0.25, 'vitamin_c': 0.0, 'vitamin_d': 12.5, 'vitamin_e': 0.025, 'tocopherol_alpha': 0.025, 'vitamin_k': 0.0, 'calcium': 0.0, 'copper': 0.2675, 'magnesium': 40.0, 'manganese': 0.1875, 'phosphorous': 262.5, 'potassium': 897.5, 'selenium': 5.5, 'protein': 6.65, 'carbohydrate': 19.525, 'fiber': 6.75, 'sugars': 0.55, 'fat': 0.725, 'saturated_fatty_acids': 0.05, 'water': 220.85}\n",
      "{'Ingredient name': 'Gochujang', 'Grams': 120, 'calories': 0, 'total_fat': 0, 'fat': 0, 'saturated_fat': 0, 'saturated_fatty_acids': 0, 'cholesterol': 0, 'sodium': 0, 'carbohydrate': 0, 'fiber': 0, 'sugars': 0, 'protein': 0, 'vitamin_a': 0, 'vitamin_a_rae': 0, 'carotene_alpha': 0, 'carotene_beta': 0, 'cryptoxanthin_beta': 0, 'lutein_zeaxanthin': 0, 'lucopene': 0, 'vitamin_b12': 0, 'vitamin_b6': 0, 'vitamin_c': 0, 'vitamin_d': 0, 'vitamin_e': 0, 'tocopherol_alpha': 0, 'vitamin_k': 0, 'calcium': 0, 'copper': 0, 'iron': 0, 'magnesium': 0, 'manganese': 0, 'phosphorous': 0, 'potassium': 0, 'selenium': 0, 'zinc': 0, 'water': 0}\n",
      "{'Ingredient name': 'Soy sauce', 'Grams': 60, 'total_fat': 0.06, 'cholesterol': 0.0, 'sodium': 3351.6, 'vitamin_a': 0.0, 'vitamin_a_rae': 0.0, 'carotene_alpha': 0.0, 'carotene_beta': 0.0, 'cryptoxanthin_beta': 0.0, 'lutein_zeaxanthin': 0.0, 'vitamin_b12': 0.0, 'vitamin_b6': 0.12, 'vitamin_c': 0.0, 'vitamin_d': 0.0, 'vitamin_e': 0.0, 'tocopherol_alpha': 0.0, 'vitamin_k': 0.0, 'calcium': 12.0, 'copper': 0.08100000000000002, 'magnesium': 24.0, 'manganese': 0.2994, 'phosphorous': 78.0, 'potassium': 127.2, 'selenium': 0.48, 'protein': 6.306, 'carbohydrate': 3.3420000000000005, 'fiber': 0.48, 'sugars': 1.02, 'fat': 0.06, 'saturated_fatty_acids': 0.006599999999999999, 'water': 39.6}\n",
      "{'Ingredient name': 'Rice vinegar', 'Grams': 60, 'total_fat': 0.12, 'cholesterol': 0.0, 'sodium': 11.4, 'vitamin_a': 0.0, 'vitamin_a_rae': 0.0, 'carotene_alpha': 0.0, 'carotene_beta': 0.0, 'cryptoxanthin_beta': 0.0, 'lutein_zeaxanthin': 0.0, 'vitamin_b12': 0.0, 'vitamin_b6': 0.0036, 'vitamin_c': 0.0, 'vitamin_d': 0.0, 'vitamin_e': 0.018, 'tocopherol_alpha': 0.018, 'vitamin_k': 0.0, 'calcium': 2.4, 'copper': 0.022799999999999997, 'magnesium': 1.8, 'manganese': 0.0684, 'phosphorous': 12.0, 'potassium': 2.4, 'selenium': 2.7, 'protein': 1.074, 'carbohydrate': 14.406, 'fiber': 0.6, 'sugars': 0.018, 'fat': 0.12, 'saturated_fatty_acids': 0.0138, 'water': 44.292}\n",
      "{'Ingredient name': 'Green onions', 'Grams': 30, 'total_fat': 0.0, 'cholesterol': 0.0, 'sodium': 0.0, 'vitamin_a': 0.0, 'vitamin_a_rae': 0.0, 'carotene_alpha': 0.0, 'carotene_beta': 0.0, 'cryptoxanthin_beta': 0.0, 'lutein_zeaxanthin': 0.0, 'vitamin_b12': 0.0, 'vitamin_b6': 0.0, 'vitamin_c': 0.0, 'vitamin_d': 0.0, 'vitamin_e': 0.0, 'tocopherol_alpha': 0.0, 'vitamin_k': 0.0, 'calcium': 0.0, 'copper': 0.0, 'magnesium': 0.0, 'manganese': 0.0, 'phosphorous': 0.0, 'potassium': 0.0, 'selenium': 0.0, 'protein': 0.0, 'carbohydrate': 1.875, 'fiber': 0.0, 'sugars': 1.875, 'fat': 0.0, 'saturated_fatty_acids': 0.0, 'water': 27.21}\n",
      "{'Ingredient name': 'Crispy garlic', 'Grams': 30, 'total_fat': 0.21, 'saturated_fat': 0.06, 'cholesterol': 0.0, 'sodium': 18.0, 'vitamin_a': 0.0, 'vitamin_a_rae': 0.0, 'carotene_alpha': 0.0, 'carotene_beta': 0.0, 'cryptoxanthin_beta': 0.0, 'lutein_zeaxanthin': 0.0, 'vitamin_b12': 0.0, 'vitamin_b6': 0.4962, 'vitamin_c': 0.36, 'vitamin_d': 0.0, 'vitamin_e': 0.201, 'tocopherol_alpha': 0.201, 'vitamin_k': 0.12, 'calcium': 23.7, 'copper': 0.15990000000000001, 'magnesium': 23.1, 'manganese': 0.2937, 'phosphorous': 124.2, 'potassium': 357.9, 'selenium': 7.17, 'protein': 4.965, 'carbohydrate': 21.819000000000003, 'fiber': 2.7, 'sugars': 0.7290000000000001, 'fat': 0.21899999999999997, 'saturated_fatty_acids': 0.0747, 'water': 1.935}\n",
      "{'Ingredient name': 'Sesame oil', 'Grams': 15, 'total_fat': 4.95, 'saturated_fat': 0.705, 'cholesterol': 0.0, 'sodium': 25.05, 'vitamin_a': 0.9, 'vitamin_a_rae': 0.0, 'carotene_alpha': 0.0, 'carotene_beta': 0.45, 'cryptoxanthin_beta': 0.0, 'lutein_zeaxanthin': 0.0, 'vitamin_b12': 0.0, 'vitamin_b6': 0.07365000000000001, 'vitamin_c': 0.0, 'vitamin_d': 0.0, 'vitamin_e': 0.024, 'tocopherol_alpha': 0.024, 'vitamin_k': 0.0, 'calcium': 95.85, 'copper': 0.1425, 'magnesium': 37.65, 'manganese': 0.24134999999999998, 'phosphorous': 61.8, 'potassium': 46.05, 'selenium': 0.6, 'protein': 1.74, 'carbohydrate': 7.545, 'fiber': 1.155, 'sugars': 4.6755, 'fat': 4.994999999999999, 'saturated_fatty_acids': 0.6992999999999999, 'water': 0.33}\n",
      "{'Ingredient name': 'Sesame seeds', 'Grams': 15, 'total_fat': 7.5, 'saturated_fat': 1.05, 'cholesterol': 0.0, 'sodium': 1.65, 'vitamin_a': 1.35, 'vitamin_a_rae': 0.0, 'carotene_alpha': 0.0, 'carotene_beta': 0.75, 'cryptoxanthin_beta': 0.0, 'lutein_zeaxanthin': 0.0, 'vitamin_b12': 0.0, 'vitamin_b6': 0.11850000000000001, 'vitamin_c': 0.0, 'vitamin_d': 0.0, 'vitamin_e': 0.0375, 'tocopherol_alpha': 0.0375, 'vitamin_k': 0.0, 'calcium': 146.25, 'copper': 0.6123, 'magnesium': 52.65, 'manganese': 0.369, 'phosphorous': 94.35, 'potassium': 70.2, 'selenium': 5.16, 'protein': 2.6595, 'carbohydrate': 3.5175, 'fiber': 1.77, 'sugars': 0.045, 'fat': 7.450500000000001, 'saturated_fatty_acids': 1.04355, 'water': 0.7035000000000001}\n",
      "{'Ingredient name': 'Kimchi', 'Grams': 150, 'total_fat': 0.75, 'saturated_fat': 0.15, 'cholesterol': 0.0, 'sodium': 747.0, 'vitamin_a': 139.5, 'vitamin_a_rae': 7.5, 'carotene_alpha': 1.5, 'carotene_beta': 82.5, 'cryptoxanthin_beta': 0.0, 'lutein_zeaxanthin': 73.5, 'vitamin_b12': 0.0, 'vitamin_b6': 0.3195, 'vitamin_c': 0.0, 'vitamin_d': 0.0, 'vitamin_e': 0.165, 'tocopherol_alpha': 0.165, 'vitamin_k': 65.4, 'calcium': 49.5, 'copper': 0.036000000000000004, 'magnesium': 21.0, 'manganese': 0.0, 'phosphorous': 36.0, 'potassium': 226.5, 'selenium': 0.75, 'protein': 1.65, 'carbohydrate': 3.6, 'fiber': 2.4, 'sugars': 1.59, 'fat': 0.75, 'saturated_fatty_acids': 0.1005, 'water': 141.45}\n",
      "{'Ingredient name': 'Steamed rice', 'Grams': 200, 'total_fat': 0.4, 'cholesterol': 0.0, 'sodium': 38.0, 'vitamin_a': 0.0, 'vitamin_a_rae': 0.0, 'carotene_alpha': 0.0, 'carotene_beta': 0.0, 'cryptoxanthin_beta': 0.0, 'lutein_zeaxanthin': 0.0, 'vitamin_b12': 0.0, 'vitamin_b6': 0.012, 'vitamin_c': 0.0, 'vitamin_d': 0.0, 'vitamin_e': 0.06, 'tocopherol_alpha': 0.06, 'vitamin_k': 0.0, 'calcium': 8.0, 'copper': 0.076, 'magnesium': 6.0, 'manganese': 0.228, 'phosphorous': 40.0, 'potassium': 8.0, 'selenium': 9.0, 'protein': 3.58, 'carbohydrate': 48.02, 'fiber': 2.0, 'sugars': 0.06, 'fat': 0.4, 'saturated_fatty_acids': 0.046, 'water': 147.64}\n",
      "{'Ingredient name': 'Noodles', 'Grams': 200, 'total_fat': 0.4, 'cholesterol': 0.0, 'sodium': 38.0, 'vitamin_a': 0.0, 'vitamin_a_rae': 0.0, 'carotene_alpha': 0.0, 'carotene_beta': 0.0, 'cryptoxanthin_beta': 0.0, 'lutein_zeaxanthin': 0.0, 'vitamin_b12': 0.0, 'vitamin_b6': 0.012, 'vitamin_c': 0.0, 'vitamin_d': 0.0, 'vitamin_e': 0.06, 'tocopherol_alpha': 0.06, 'vitamin_k': 0.0, 'calcium': 8.0, 'copper': 0.076, 'magnesium': 6.0, 'manganese': 0.228, 'phosphorous': 40.0, 'potassium': 8.0, 'selenium': 9.0, 'protein': 3.58, 'carbohydrate': 48.02, 'fiber': 2.0, 'sugars': 0.06, 'fat': 0.4, 'saturated_fatty_acids': 0.046, 'water': 147.64}\n",
      "{'Ingredient name': 'Rice', 'Grams': 200, 'total_fat': 0.4, 'cholesterol': 0.0, 'sodium': 38.0, 'vitamin_a': 0.0, 'vitamin_a_rae': 0.0, 'carotene_alpha': 0.0, 'carotene_beta': 0.0, 'cryptoxanthin_beta': 0.0, 'lutein_zeaxanthin': 0.0, 'vitamin_b12': 0.0, 'vitamin_b6': 0.012, 'vitamin_c': 0.0, 'vitamin_d': 0.0, 'vitamin_e': 0.06, 'tocopherol_alpha': 0.06, 'vitamin_k': 0.0, 'calcium': 8.0, 'copper': 0.076, 'magnesium': 6.0, 'manganese': 0.228, 'phosphorous': 40.0, 'potassium': 8.0, 'selenium': 9.0, 'protein': 3.58, 'carbohydrate': 48.02, 'fiber': 2.0, 'sugars': 0.06, 'fat': 0.4, 'saturated_fatty_acids': 0.046, 'water': 147.64}\n"
     ]
    }
   ],
   "source": [
    "recipe_with_nutrients = get_best_match(ingreds['Ingredients'], df_nutritions, important_nutrients=important_nutrients)\n",
    "for ingredient in recipe_with_nutrients:\n",
    "    print(ingredient)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "nutrients_dict = defaultdict(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'calories'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[66], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m ing \u001b[38;5;129;01min\u001b[39;00m recipe_with_nutrients:\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m nu \u001b[38;5;129;01min\u001b[39;00m important_nutrients:\n\u001b[0;32m----> 3\u001b[0m         \u001b[43ming\u001b[49m\u001b[43m[\u001b[49m\u001b[43mnu\u001b[49m\u001b[43m]\u001b[49m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'calories'"
     ]
    }
   ],
   "source": [
    "for ing in recipe_with_nutrients:\n",
    "    for nu in important_nutrients:\n",
    "        ing[nu]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Ingredient name': 'Rice',\n",
       " 'Grams': 200,\n",
       " 'total_fat': 0.4,\n",
       " 'cholesterol': 0.0,\n",
       " 'sodium': 38.0,\n",
       " 'vitamin_a': 0.0,\n",
       " 'vitamin_a_rae': 0.0,\n",
       " 'carotene_alpha': 0.0,\n",
       " 'carotene_beta': 0.0,\n",
       " 'cryptoxanthin_beta': 0.0,\n",
       " 'lutein_zeaxanthin': 0.0,\n",
       " 'vitamin_b12': 0.0,\n",
       " 'vitamin_b6': 0.012,\n",
       " 'vitamin_c': 0.0,\n",
       " 'vitamin_d': 0.0,\n",
       " 'vitamin_e': 0.06,\n",
       " 'tocopherol_alpha': 0.06,\n",
       " 'vitamin_k': 0.0,\n",
       " 'calcium': 8.0,\n",
       " 'copper': 0.076,\n",
       " 'magnesium': 6.0,\n",
       " 'manganese': 0.228,\n",
       " 'phosphorous': 40.0,\n",
       " 'potassium': 8.0,\n",
       " 'selenium': 9.0,\n",
       " 'protein': 3.58,\n",
       " 'carbohydrate': 48.02,\n",
       " 'fiber': 2.0,\n",
       " 'sugars': 0.06,\n",
       " 'fat': 0.4,\n",
       " 'saturated_fatty_acids': 0.046,\n",
       " 'water': 147.64}"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_prompt_template = \"The user is living in {user_location}. The user is looking for a {user_query}. Here is a generated recipe: {generated_recipes}. Generate all ingredients with their corresponding unit and amount in the recipe.\"\n",
    "\n",
    "eval_prompt = eval_prompt_template.format(user_location=user_location, user_query=user_query, generated_recipes=concat_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema_eval = r'''\n",
    "root ::= (\n",
    "    \"{\" newline\n",
    "        doublespace \"\\\"Results\\\":\" space boolean \",\" newline\n",
    "        doublespace \"\\\"Reasons\\\":\" space string newline\n",
    "    \"}\"\n",
    ")\n",
    "newline ::= \"\\n\"\n",
    "doublespace ::= \"  \"\n",
    "number ::= [0-9]+   \".\"?   [0-9]*\n",
    "integer ::= [0-9]*\n",
    "boolean ::= \"true\" | \"false\"\n",
    "char ::= [^\"\\\\\\x7F\\x00-\\x1F] | [\\\\] ([\"\\\\bfnrt] | \"u\" [0-9a-fA-F]{4})\n",
    "space ::= | \" \" | \"\\n\" [ \\t]{0,20}\n",
    "string ::= \"\\\"\" char* \"\\\"\" space\n",
    "sentence ::= char* space\n",
    "listofstring ::= (\"[\" space (string (\",\" space string)*)? \"]\")\n",
    "cookstep ::= (\"\\\"Step\" space integer \"\\\"\" \":\" space string)\n",
    "cookinstructs ::= (space \"{\" space (cookstep (\",\" space cookstep){10})? \"}\")\n",
    "ingredname ::= (\"\\\"Ingredient name\" space \"\\\"\" \":\" space string)\n",
    "ingredunit ::= (\"\\\"Unit\" space \"\\\"\" \":\" space string)\n",
    "ingredamt ::= (\"\\\"Amount\" space \"\\\"\" \":\" space number)\n",
    "ingredset ::= (\"{\" ingredname \",\" space ingredunit \",\" space ingredamt space \"}\")\n",
    "ingreds ::= (space \"[\" space (ingredset (\",\" space ingredset){20})? \"]\")\n",
    "'''\n",
    "\n",
    "grammar_recipe = LlamaGrammar.from_string(grammar=schema_recipe, verbose=False)\n",
    "\n",
    "\n",
    "result = llm.create_chat_completion(\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"You are a helpful assistant that outputs in JSON. You are provided with a recipe and its corresponding nutrition. Evaluate whether the nutrition is following the requirements.\",\n",
    "        },\n",
    "        {\"role\": \"user\", \"content\": eval_prompt},\n",
    "    ],\n",
    "    grammar=grammar_recipe,\n",
    "    temperature=0.7,\n",
    "    stream=True\n",
    ")\n",
    "\n",
    "for chunk in result:\n",
    "    delta = chunk['choices'][0]['delta']\n",
    "    if 'role' in delta:\n",
    "        print(delta['role'], end=': ')\n",
    "    elif 'content' in delta:\n",
    "        print(delta['content'], end='')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
